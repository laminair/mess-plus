run_name: "baseline"
seed: 42

model_zoo:
  meta-llama/Llama-3.2-1B-Instruct:
    category: "small"
    gpu_indices: [0]
    max_seq_len: 2048
    gpu_memory_utilization: 0.45
    quantization: null
  unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit:
    category: "medium"
    gpu_indices: [0]
    max_seq_len: 2048
    gpu_memory_utilization: 0.45
    quantization: "bitsandbytes"
#  meta-llama/Llama-3.3-70B-Instruct:
#    category: "large"
#    gpu_indices: [0]
#    max_seq_len: 2048

classifier_model:
  model_id: "answerdotai/ModernBERT-base"
  max_seq_len: 1024
  hidden_layer_shape: [512]
  optimizer: "adam"
  beta1: 0.9
  beta2: 0.99
  lr: 0.0001
  minibatch_size: 1
  epochs: 1
  reweight_classes: true
  gamma: 2
  gpu_index: 0

algorithm:
  alpha: 0.8
  c: 1
  V: 100

lm_eval:
  # The run name will be the first benchmark in the list below.
  benchmarks: ["boolq"]
  limit_num_samples: 1000
