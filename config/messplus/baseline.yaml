run_name: "baseline"

model_zoo:
  meta-llama/Llama-3.2-1B-Instruct:
    category: "small"
    gpu_indices: [0]
    max_seq_len: 2048
  meta-llama/Llama-3.2-3B-Instruct:
    category: "medium"
    gpu_indices: [0]
    max_seq_len: 2048
#  meta-llama/Llama-3.1-8B-Instruct:
#    category: "large"
#    gpu_indices: [0]
#    max_seq_len: 2048

# TODO: @Ryan can you please find out what system prompt they are using in LM Eval for each dataset that we want to use?
system_prompt: "You are a helpful chatbot that can answer with either 'A' or 'B' only. Which option do you choose?"

classifier_model:
  model_id: "answerdotai/ModernBERT-base"
  max_seq_len: 1024
  # This corresponds to the number of model categories (e.g., small, medium, large) in the model_zoo plus
  # the additional option that we need human annotation, i.e., the most expensive option.
  num_labels: 3
  classifier_layer_hidden_dims: [128]

algorithm:
  alpha: 0.8
  c: 1