{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e5ded1-75e3-4227-9a02-0693da426c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7ad20a-19b8-4f13-86f5-435291daa8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = [\n",
    "    \"meta-llama__Llama-3.2-1B-Instruct_chosen\",\n",
    "    \"meta-llama__Llama-3.2-3B-Instruct_chosen\",\n",
    "    \"meta-llama__Llama-3.1-8B-Instruct_chosen\",\n",
    "    \"meta-llama__Llama-3.1-70B-Instruct_chosen\",\n",
    "    \"meta-llama__Llama-3.3-70B-Instruct_chosen\",\n",
    "]\n",
    "\n",
    "INPUT_FOLDER = Path(\"datasets\")\n",
    "OUTPUT_FOLDER = Path(\"datasets/csv\")\n",
    "OUTPUT_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "FILE_SELECTION_PATTERN = re.compile(r\"samples_(.*?)_\\d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf4a18d-06ae-404e-84c7-a9511e3ce772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF = pd.DataFrame()\n",
    "for model_dir in INPUT_FOLDER.iterdir():\n",
    "    model_df = pd.DataFrame()\n",
    "    if not model_dir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    for jsonl_file in model_dir.glob(\"*.jsonl\"):\n",
    "        match = FILE_SELECTION_PATTERN.match(jsonl_file.name)\n",
    "        \n",
    "        if not match:\n",
    "            print(f\"Skipping file (doesn't match pattern): {filename}\")\n",
    "            continue\n",
    "\n",
    "        dataset_name = match.group(1)\n",
    "\n",
    "        model_name = model_dir.name\n",
    "\n",
    "        f = pd.read_json(jsonl_file, lines=True)\n",
    "        f[\"input_text\"] = f[\"doc\"].apply(lambda x: x[\"question\"])\n",
    "        try: \n",
    "            f[\"choices\"] = f[\"doc\"].apply(lambda x: x[\"choices\"])\n",
    "        except KeyError as e: \n",
    "            try:\n",
    "                f[\"choices\"] = f[\"doc\"].apply(lambda x: [\"yes\", \"no\"])\n",
    "            except KeyError as e:\n",
    "                display(f[\"doc\"][0]) \n",
    "                raise e\n",
    "\n",
    "        try: \n",
    "            f[\"correct_response\"] = f[\"doc\"].apply(lambda x: x[\"answer\"])\n",
    "        except KeyError as e: \n",
    "            try:\n",
    "                f[\"correct_response\"] = f[\"doc\"].apply(lambda x: x[\"label\"])\n",
    "            except KeyError as e:\n",
    "                display(f[\"doc\"][0]) \n",
    "                raise e\n",
    "\n",
    "        try: \n",
    "            f[\"subject\"] = f[\"doc\"].apply(lambda x: x[\"subject\"])\n",
    "        except KeyError as e: \n",
    "            f[\"subject\"] = \"N/A\"\n",
    "        \n",
    "        f[\"dataset\"] = dataset_name\n",
    "        f[f\"{model_dir.name}_correct\"] = f[\"acc\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "        model_df = pd.concat([\n",
    "            model_df, \n",
    "            f[[\"input_text\", \"dataset\", \"choices\", \"correct_response\", \"subject\", f\"{model_dir.name}_correct\"]]\n",
    "        ])\n",
    "\n",
    "    if len(model_df) == 0:\n",
    "        continue\n",
    "        \n",
    "    if len(DF) > 0:\n",
    "        DF = DF.merge(model_df[[\"input_text\", f\"{model_dir.name}_correct\"]], on=\"input_text\", how=\"inner\")\n",
    "    else: \n",
    "        DF = model_df.copy(deep=True)\n",
    "\n",
    "COLUMNS = DF.columns \n",
    "MODEL_COLS = [i for i in COLUMNS if \"meta-llama\" in i]\n",
    "COLS = []\n",
    "for i in MODEL_COLS:\n",
    "    i_split = i.split(\"-\")\n",
    "    param_count = i_split[3] if len(i_split[3]) == 3 else f\"0{i_split[3]}\"\n",
    "    \n",
    "    COLS.append(\n",
    "        f\"llama_{param_count}_{i_split[2].replace('.', '')}\"\n",
    "    )\n",
    "\n",
    "NON_MODEL_COLS = [i for i in COLUMNS if \"meta-llama\" not in i]\n",
    "COLUMNS = NON_MODEL_COLS + COLS\n",
    "DF.columns = COLUMNS\n",
    "\n",
    "MODEL_COLS = [i for i in COLUMNS if \"llama_\" in i]\n",
    "SORTED_MODEL_COLS = sorted(MODEL_COLS)\n",
    "DF = DF[NON_MODEL_COLS + SORTED_MODEL_COLS]\n",
    "\n",
    "DF[\"label\"] = DF.apply(lambda row: [row[i] for i in SORTED_MODEL_COLS], axis=1)\n",
    "\n",
    "DF.to_csv(f\"{OUTPUT_FOLDER}/all_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261dfcbe-70bd-49a3-8962-f55774352317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e09cfd-3dff-4b9e-8645-26295bd94d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d3460-e526-45ef-b050-c1e9b3f9b7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb4e6c-94d2-4c14-bf82-5b5d69c13b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1710a-03d4-4d68-bf3c-e412fcfffebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_to_csv(jsonl_path, csv_path):\n",
    "    \"\"\"\n",
    "    Read a .jsonl file, gather all keys from all lines,\n",
    "    and write out a CSV with those columns.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    all_keys = set()\n",
    "\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            data = json.loads(line)\n",
    "            rows.append(data)\n",
    "            all_keys.update(data.keys())\n",
    "\n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8') as out_f:\n",
    "        writer = csv.DictWriter(out_f, fieldnames=sorted(all_keys))\n",
    "        writer.writeheader()\n",
    "        for row in rows:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb63af-1acd-4267-a595-eca467bb135d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for jsonl_file in OUTPUT_FOLDER.glob(\"*.jsonl\"):\n",
    "    dataset_name = jsonl_file.stem \n",
    "    csv_file = OUTPUT_FOLDER / f\"{dataset_name}.csv\"\n",
    "\n",
    "    # print(f\"Converting {jsonl_file} -> {csv_file} ...\")\n",
    "    jsonl_to_csv(jsonl_file, csv_file)\n",
    "    # print(f\"Saved {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b65845-cd3a-4746-b3f6-1b7070d92ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOLQ = pd.read_csv(f\"{OUTPUT_FOLDER}/boolq.csv\")\n",
    "LOGIQA2 = pd.read_csv(f\"{OUTPUT_FOLDER}/logiqa2.csv\")\n",
    "\n",
    "MMLU_FILES = glob.glob(f\"{OUTPUT_FOLDER}/mmlu_*.csv\")\n",
    "MMLU = pd.DataFrame()\n",
    "for file in MMLU_FILES:\n",
    "    MMLU = pd.concat([MMLU, pd.read_csv(file)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5ee910-f03f-4121-8d00-f65352cf4890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "31440"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "280840"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(BOOLQ))\n",
    "display(len(LOGIQA2))\n",
    "display(len(MMLU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ae27c76-0ce0-4de1-a483-3b80a6a96187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>arguments</th>\n",
       "      <th>doc</th>\n",
       "      <th>doc_hash</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>filter</th>\n",
       "      <th>filtered_resps</th>\n",
       "      <th>metrics</th>\n",
       "      <th>model_name</th>\n",
       "      <th>prompt_hash</th>\n",
       "      <th>resps</th>\n",
       "      <th>target</th>\n",
       "      <th>target_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>{'gen_args_0': {'arg_0': \"Ethanol fuel -- All ...</td>\n",
       "      <td>{'question': 'does ethanol take more energy ma...</td>\n",
       "      <td>34c12031b4c7298fa36fd4bd2d8f2a482ec2fa5b8849bf...</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>[['-3.78125', 'False'], ['-3.28125', 'False']]</td>\n",
       "      <td>['acc']</td>\n",
       "      <td>meta-llama__Llama-3.1-70B-Instruct</td>\n",
       "      <td>99815785e839d379cc9330a0be56ce32e4956ac9aae467...</td>\n",
       "      <td>[[['-3.78125', 'False']], [['-3.28125', 'False...</td>\n",
       "      <td>0</td>\n",
       "      <td>5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc                                          arguments  \\\n",
       "0  0.0  {'gen_args_0': {'arg_0': \"Ethanol fuel -- All ...   \n",
       "\n",
       "                                                 doc  \\\n",
       "0  {'question': 'does ethanol take more energy ma...   \n",
       "\n",
       "                                            doc_hash  doc_id filter  \\\n",
       "0  34c12031b4c7298fa36fd4bd2d8f2a482ec2fa5b8849bf...       0   none   \n",
       "\n",
       "                                   filtered_resps  metrics  \\\n",
       "0  [['-3.78125', 'False'], ['-3.28125', 'False']]  ['acc']   \n",
       "\n",
       "                           model_name  \\\n",
       "0  meta-llama__Llama-3.1-70B-Instruct   \n",
       "\n",
       "                                         prompt_hash  \\\n",
       "0  99815785e839d379cc9330a0be56ce32e4956ac9aae467...   \n",
       "\n",
       "                                               resps  target  \\\n",
       "0  [[['-3.78125', 'False']], [['-3.28125', 'False...       0   \n",
       "\n",
       "                                         target_hash  \n",
       "0  5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(BOOLQ.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ecd0bf2-dd8b-47a0-a2dd-1385591c3229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'gen_args_0\\': {\\'arg_0\\': \"Ethanol fuel -- All biomass goes through at least some of these steps: it needs to be grown, collected, dried, fermented, distilled, and burned. All of these steps require resources and an infrastructure. The total amount of energy input into the process compared to the energy released by burning the resulting ethanol fuel is known as the energy balance (or ``energy returned on energy invested\\'\\'). Figures compiled in a 2007 report by National Geographic Magazine point to modest results for corn ethanol produced in the US: one unit of fossil-fuel energy is required to create 1.3 energy units from the resulting ethanol. The energy balance for sugarcane ethanol produced in Brazil is more favorable, with one unit of fossil-fuel energy required to create 8 from the ethanol. Energy balance estimates are not easily produced, thus numerous such reports have been generated that are contradictory. For instance, a separate survey reports that production of ethanol from sugarcane, which requires a tropical climate to grow productively, returns from 8 to 9 units of energy for each unit expended, as compared to corn, which only returns about 1.34 units of fuel energy for each unit of energy expended. A 2006 University of California Berkeley study, after analyzing six separate studies, concluded that producing ethanol from corn uses much less petroleum than producing gasoline.\\\\nQuestion: does ethanol take more energy make that produces?\\\\nAnswer:\", \\'arg_1\\': \\' no\\'}, \\'gen_args_1\\': {\\'arg_0\\': \"Ethanol fuel -- All biomass goes through at least some of these steps: it needs to be grown, collected, dried, fermented, distilled, and burned. All of these steps require resources and an infrastructure. The total amount of energy input into the process compared to the energy released by burning the resulting ethanol fuel is known as the energy balance (or ``energy returned on energy invested\\'\\'). Figures compiled in a 2007 report by National Geographic Magazine point to modest results for corn ethanol produced in the US: one unit of fossil-fuel energy is required to create 1.3 energy units from the resulting ethanol. The energy balance for sugarcane ethanol produced in Brazil is more favorable, with one unit of fossil-fuel energy required to create 8 from the ethanol. Energy balance estimates are not easily produced, thus numerous such reports have been generated that are contradictory. For instance, a separate survey reports that production of ethanol from sugarcane, which requires a tropical climate to grow productively, returns from 8 to 9 units of energy for each unit expended, as compared to corn, which only returns about 1.34 units of fuel energy for each unit of energy expended. A 2006 University of California Berkeley study, after analyzing six separate studies, concluded that producing ethanol from corn uses much less petroleum than producing gasoline.\\\\nQuestion: does ethanol take more energy make that produces?\\\\nAnswer:\", \\'arg_1\\': \\' yes\\'}}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOOLQ[\"arguments\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecdb36e-f5ed-4376-bd25-72355173a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolq.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d64cb0-d56d-442d-a2ad-c0ef252a0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_model = boolq.groupby('model_name')['acc'].mean()\n",
    "\n",
    "print(accuracy_per_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794bfbb-d982-44f5-b0a4-d77283e6e297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets_dir = Path(\"data/lm_eval_harness_output\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for dataset_file in datasets_dir.glob(\"*.csv\"):\n",
    "    dataset_name = dataset_file.stem\n",
    "    df = pd.read_csv(dataset_file)\n",
    "    accuracy = df.groupby(\"model_name\")[\"acc\"].mean()\n",
    "    results[dataset_name] = accuracy\n",
    "\n",
    "summary_df = pd.DataFrame(results).T.fillna(0)\n",
    "summary_df = summary_df[model_order]\n",
    "\n",
    "plt.figure(figsize=(12, max(2, len(summary_df) * 0.5)))\n",
    "summary_df.plot(kind=\"barh\", figsize=(12, max(2, len(summary_df) * 0.5)), width=0.8)\n",
    "plt.title(\"Model Accuracy per Dataset\", fontsize=16)\n",
    "plt.xlabel(\"Accuracy\", fontsize=14)\n",
    "plt.ylabel(\"Dataset\", fontsize=14)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.legend(title=\"Model\", bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a6535-260c-4043-ad7f-0358115f4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_input_text(doc_str):\n",
    "    data = ast.literal_eval(doc_str)\n",
    "    question = data.get(\"question\", \"\")\n",
    "    passage = data.get(\"passage\", \"\")\n",
    "    return f\"{question} {passage}\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa4367-906f-4afe-b836-a0a26886effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolq[\"input_text\"] = boolq[\"doc\"].apply(extract_input_text)\n",
    "boolq.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03009e69-9150-48e1-a9e1-bf01487b7978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boolq[\"input_text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c057b5a-aafb-423d-87c1-1fd6862fca16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets_dir = Path(\"data/lm_eval_harness_output\")\n",
    "\n",
    "for csv_file in datasets_dir.glob(\"*.csv\"):\n",
    "    print(f\"Processing {csv_file.name}...\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    if \"doc\" in df.columns:\n",
    "        df[\"input_text\"] = df[\"doc\"].apply(extract_input_text)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"Updated {csv_file.name}.\")\n",
    "    else:\n",
    "        print(f\"Skipping {csv_file.name}: No 'doc' column.\")\n",
    "\n",
    "print(\"All files processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39addc38-955c-4072-9849-9a718e140885",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_medical_genetics = pd.read_csv(\"data/lm_eval_harness_output/modern-bert-embeddings/mmlu_medical_genetics_embeds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb91c6-8c89-44be-8f74-36641dcb877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_medical_genetics[\"input_text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f249a-042b-4a2e-b92a-c392da0b4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_to_find = 'If the frequency of males affected with an X-linked recessive condition in a human population is .10 (one in ten), what will be the expected frequency of affected females?'\n",
    "\n",
    "count = (mmlu_medical_genetics[\"input_text\"] == input_text_to_find).sum()\n",
    "print(f\"The input text appears {count} times in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e49a14-237c-491f-b4c2-f6cec718fc72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def combine_rows(group):\n",
    "    combined_row = group.iloc[0].drop([\"acc\", \"model_name\", \"arguments\"]).to_dict()\n",
    "    combined_row[\"arguments\"] = \" \".join(group[\"arguments\"])\n",
    "    for _, row in group.iterrows():\n",
    "        combined_row[f\"{row['model_name']}_chosen\"] = row[\"acc\"]\n",
    "    return pd.Series(combined_row)\n",
    "\n",
    "grouped_df = (\n",
    "    mmlu_medical_genetics.groupby(\"input_text\", as_index=False)\n",
    "    .apply(combine_rows)\n",
    ")\n",
    "\n",
    "existing_columns = [col for col in grouped_df.columns if col not in model_order]\n",
    "grouped_df = grouped_df[existing_columns + model_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225ae21-6cf5-4693-a2d8-85f083b0c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f774d82-4814-423a-b49f-b29541a541a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets_dir = Path(\"data/lm_eval_harness_output/modern-bert-embeddings/\")\n",
    "\n",
    "for csv_file in datasets_dir.glob(\"*.csv\"):\n",
    "    print(f\"Processing {csv_file}...\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    grouped_df = (\n",
    "        df.groupby(\"input_text\", as_index=False)\n",
    "        .apply(combine_rows)\n",
    "    )\n",
    "    existing_columns = [col for col in grouped_df.columns if col not in model_order]\n",
    "    grouped_df = grouped_df[existing_columns + model_order]\n",
    "    grouped_df.to_csv(csv_file, index=False)\n",
    "    print(f\"Saved updated file: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f696c3-6925-4af5-941a-575f8bd9b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "logiqa2 = pd.read_csv(\"data/lm_eval_harness_output/modern-bert-embeddings/logiqa2_embeds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e07e44-2d55-49fb-ad06-bd9466d4275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_chosen_model_numeric(row, model_order):\n",
    "    for idx, model in enumerate(model_order, start=1):\n",
    "        if row[model] == 1:  \n",
    "            return idx\n",
    "    return len(model_order)  \n",
    "\n",
    "logiqa2[\"chosen_model\"] = logiqa2.apply(lambda row: determine_chosen_model_numeric(row, model_order), axis=1).astype(int)\n",
    "logiqa2.to_csv(\"data/lm_eval_harness_output/modern-bert-embeddings/logiqa2_embeds.csv\", index=False)\n",
    "print(\"Added 'chosen_model' column with integer labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688695d1-bde3-4131-ad56-c5da34f88770",
   "metadata": {},
   "outputs": [],
   "source": [
    "logiqa2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd120e67-3a7d-413a-a006-973ace08dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dir = Path(\"datasets/modern-bert-embeddings\")\n",
    "\n",
    "for csv_file in datasets_dir.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df[\"chosen_model\"] = df.apply(lambda row: determine_chosen_model_numeric(row, model_order), axis=1).astype(int)\n",
    "    df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726dbfb9-228a-4162-aa56-5d9e2da7626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolq = pd.read_csv(\"datasets/modern-bert-embeddings/boolq_embeds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9057e12-1322-446a-b908-82732b2d34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58e282-1488-422e-a64c-803e1c0f6e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
