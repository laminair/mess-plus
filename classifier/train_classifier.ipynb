{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import wandb\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from classifier.file_reader import read_files_from_folder\n",
    "from classifier.dataset import BertPandasDataset, collate_fn, create_bert_datasets, preprocess_dataframe\n",
    "from classifier.model import ContinualMultilabelBERTClassifier, MultilabelBERTClassifier\n",
    "\n",
    "FOLDER_PATH = Path(\"train_classifier.ipynb\").parent.absolute()\n",
    "print(FOLDER_PATH)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "DATASET = \"boolq\"\n",
    "MODEL_NAME = \"answerdotai/ModernBERT-base\"\n",
    "MINIBATCH_SIZE = 64\n",
    "N_EPOCHS = 50\n",
    "TEST_VAL_SET_SIZE = 0.15\n",
    "\n",
    "benchmark_config_path = Path(f\"{FOLDER_PATH.parent}/config/messplus/boolq.yaml\")\n",
    "\n",
    "# Read and parse the YAML file\n",
    "with benchmark_config_path.open(\"r\") as f:\n",
    "    classifier_config = yaml.safe_load(f)[\"classifier_model\"]\n",
    "\n",
    "f.close()\n",
    "\n",
    "df = read_files_from_folder(f\"{FOLDER_PATH.parent}/data/inference_outputs/boolq\", file_ext=\".csv\")\n",
    "display(df.head())"
   ],
   "id": "5b9cddcf0cc851b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(len(df[\"input_text\"]))",
   "id": "61c14d00def0269c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text_col = [\"input_text\"]\n",
    "label_cols = [\"label_small\", \"label_medium\"]\n",
    "\n",
    "dataset = df[text_col + label_cols]\n",
    "dataset = preprocess_dataframe(dataset, label_cols=label_cols)\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset, val_dataset, tokenizer = create_bert_datasets(\n",
    "    dataset,\n",
    "    text_col,\n",
    "    label_cols,\n",
    "    model_name=MODEL_NAME,\n",
    "    max_length=1024,\n",
    "    val_ratio=0.10,\n",
    ")\n",
    "\n",
    "# Create DataLoaders with the custom collate function\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "display(f\"Training dataset size: {len(train_dataset)}\")\n",
    "display(f\"Validation dataset size: {len(val_dataset)}\")"
   ],
   "id": "8d8d8e017b1a5fb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Full model training\n",
    "Training the full model yields strong results but shows overfitting behavior very quickly.\n",
    "We also exhibit local batch instabilities (observable from loss spikes).\n",
    "I tried to adjust the classifier architecture to account for those instabilities.\n",
    "We might need some form of regularization to treat the losses."
   ],
   "id": "4b88053b473f5c7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classifier = MultilabelBERTClassifier(\n",
    "    model_name=MODEL_NAME,  # Replace with your preferred BERT variant\n",
    "    num_labels=len(label_cols),\n",
    "    learning_rate=1e-3,\n",
    "    momentum=0.85,\n",
    "    weight_decay=0.01,\n",
    "    batch_size=16,\n",
    "    max_length=128,\n",
    "    warmup_ratio=0.05,\n",
    "    threshold=0.5,\n",
    "    freeze_bert_layers=True,\n",
    "    config=classifier_config,\n",
    ")\n",
    "\n",
    "with wandb.init(\n",
    "    entity=\"tum-i13\",\n",
    "    project=\"mess-plus-classifier-training-offline\",\n",
    "    name=\"minibatch_size-16-mom-0.9\"\n",
    "):\n",
    "\n",
    "    # Train the model\n",
    "    classifier.fit(train_dataset, val_dataset, epochs=1, early_stopping_patience=2)\n",
    "\n",
    "wandb.finish()\n"
   ],
   "id": "53ab35c56cf81282",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classifier.predict(texts=[\n",
    "    \"does ethanol take more energy make that produces\",\n",
    "    \"is the liver part of the excretory system\"\n",
    "])"
   ],
   "id": "67502ebaf78d982f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Continuous learning approach",
   "id": "96b421bb628db007"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# cont_model = ContinualMultilabelBERTClassifier(\n",
    "#     model_name=MODEL_NAME,  # Replace with your preferred BERT variant\n",
    "#     num_labels=len(label_cols),\n",
    "#     learning_rate=8e-7,\n",
    "#     weight_decay=0.01,\n",
    "#     batch_size=16,\n",
    "#     max_length=128,\n",
    "#     warmup_ratio=0.1,\n",
    "#     threshold=0.5,\n",
    "#     freeze_bert_layers=True,\n",
    "#     memory_size=0\n",
    "# )\n",
    "#\n",
    "#\n",
    "# for idx in range(len(dataset)):\n",
    "#     print(f\"Fetching sample {idx}/{len(dataset)}...\")\n",
    "#     sample = BertPandasDataset(df.loc[idx], text_col, label_cols, tokenizer, 128)\n",
    "#     cont_model.incremental_fit(\n",
    "#         new_train_dataset=sample,\n",
    "#         new_val_dataset=val_dataset,\n",
    "#     )\n",
    "#\n",
    "#     if idx % 50 == 0 and idx != 0:\n",
    "#         display(f\"Done.\")\n",
    "#         break\n"
   ],
   "id": "4704d291d21b380",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
