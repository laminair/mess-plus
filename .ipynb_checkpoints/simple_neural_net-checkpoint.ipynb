{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4aa7fdb-9be5-4a8b-9fa4-4ca3bed0c4ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in /home/ubuntu/.local/lib/python3.8/site-packages (0.7.4)\n",
      "Requirement already satisfied: seaborn in /home/ubuntu/.local/lib/python3.8/site-packages (0.13.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from textstat) (45.2.0)\n",
      "Requirement already satisfied: pyphen in /home/ubuntu/.local/lib/python3.8/site-packages (from textstat) (0.16.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/ubuntu/.local/lib/python3.8/site-packages (from seaborn) (1.24.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/ubuntu/.local/lib/python3.8/site-packages (from seaborn) (3.7.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (20.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.0.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (7.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /home/ubuntu/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2->seaborn) (1.14.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home/ubuntu/.local/lib/python3.8/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24869fc1-fbfc-4155-8db1-b7280fd62247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade numpy scipy nltk scikit-learn textstat torch pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61013ddc-e789-4bbd-90b6-824afda3f680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import textstat\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf103d-3321-4c64-aa75-173dfd3f899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(text):\n",
    "    return {\n",
    "        \"flesch_reading_ease\": textstat.flesch_reading_ease(text),\n",
    "        \"gunning_fog\": textstat.gunning_fog(text),\n",
    "        \"smog_index\": textstat.smog_index(text),\n",
    "        \"automated_readability_index\": textstat.automated_readability_index(text),\n",
    "        \"lexical_diversity\": len(set(text.split())) / len(text.split()) if len(text.split()) > 0 else 0,\n",
    "        \"syllable_count\": textstat.syllable_count(text),\n",
    "        \"complex_word_count\": textstat.difficult_words(text),\n",
    "        \"avg_word_length\": sum(len(word) for word in text.split()) / len(text.split()) if len(text.split()) > 0 else 0,\n",
    "        \"sentence_length\": len(text.split())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8429ec-e6ec-47d0-b713-9d86d74a6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"This is an example sentence to evaluate.\"\n",
    "metrics = compute_metrics(sentence)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59f615-b779-4e02-b965-77ef60414e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"This is an example.\"\n",
    "avg_word_length = sum(len(word) for word in sentence.split()) / len(sentence.split())\n",
    "print(f\"Average word length: {avg_word_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a4398-4579-4387-9b2f-34c3200efc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_logs/wmt14_bleu_threshold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe9e6c-23cc-4560-8184-78e564952e7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metrics = df['input_text'].apply(compute_metrics).apply(pd.Series)\n",
    "df = pd.concat([df, df_metrics], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea1912-8a61-4f47-8cd1-add7e305d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177838f0-8bc0-4a93-ae90-0829ca9f6d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83ac9e-0dac-4ce3-a231-fdc5267477a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"flesch_reading_ease\", \"gunning_fog\", \"smog_index\", \n",
    "    \"automated_readability_index\", \"lexical_diversity\", \n",
    "    \"syllable_count\", \"complex_word_count\", \"avg_word_length\", \n",
    "    \"sentence_length\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55c8c4-9599-43e3-9d97-d5abdaf59524",
   "metadata": {},
   "outputs": [],
   "source": [
    "can_handle_df = df[df['1b'] == 1]\n",
    "cannot_handle_df = df[df['1b'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b7ee4-bc02-4555-b3d5-c58eed530a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(can_handle_df[metric], color='blue', alpha=0.5, bins=30, kde=True, label='Can Handle')\n",
    "    sns.histplot(cannot_handle_df[metric], color='red', alpha=0.5, bins=30, kde=True, label='Cannot Handle')\n",
    "    plt.title(f\"Distribution of {metric}\")\n",
    "    plt.xlabel(metric)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c620b96-6937-4751-a118-d83b00477af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_results = {}\n",
    "for metric in metrics:\n",
    "    correlation_results[metric] = df[metric].corr(df['1b'])\n",
    "print(\"Correlations with '1b':\", correlation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fd9106b-c908-4793-b133-4fdaa2ac8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b55a6d0f-eafc-454e-a296-aec241ca6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = ['input_text', '1b', '3b', '8b']\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[['1b', '3b', '8b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cbb4edc-0470-43ac-83f9-8634f400d97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3eb4e9e-a6e8-4fa6-b3ba-54dabc45f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebe44aa7-1d98-4a80-9f7d-71b4c2ef2272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2e94e9b-1eb6-4a59-9051-be48f74a830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efe1d38b-571e-4731-879b-7d0d791b5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1eb224cb-de8b-47b6-80ee-6fb42ae0f97a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleNet(input_dim=len(feature_cols)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6eb589c2-edb9-4ea9-8289-4a5e35c5fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE_loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba72a2c7-06cd-46e8-8474-639ccc6e0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7322e9b7-f524-48fa-b1ef-aeab17566c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.6813, Val Loss: 0.6640\n",
      "Epoch 2/100, Train Loss: 0.6465, Val Loss: 0.6324\n",
      "Epoch 3/100, Train Loss: 0.6167, Val Loss: 0.6049\n",
      "Epoch 4/100, Train Loss: 0.5907, Val Loss: 0.5809\n",
      "Epoch 5/100, Train Loss: 0.5682, Val Loss: 0.5604\n",
      "Epoch 6/100, Train Loss: 0.5492, Val Loss: 0.5433\n",
      "Epoch 7/100, Train Loss: 0.5336, Val Loss: 0.5293\n",
      "Epoch 8/100, Train Loss: 0.5209, Val Loss: 0.5179\n",
      "Epoch 9/100, Train Loss: 0.5107, Val Loss: 0.5088\n",
      "Epoch 10/100, Train Loss: 0.5025, Val Loss: 0.5014\n",
      "Epoch 11/100, Train Loss: 0.4958, Val Loss: 0.4954\n",
      "Epoch 12/100, Train Loss: 0.4904, Val Loss: 0.4904\n",
      "Epoch 13/100, Train Loss: 0.4859, Val Loss: 0.4863\n",
      "Epoch 14/100, Train Loss: 0.4821, Val Loss: 0.4828\n",
      "Epoch 15/100, Train Loss: 0.4790, Val Loss: 0.4799\n",
      "Epoch 16/100, Train Loss: 0.4762, Val Loss: 0.4774\n",
      "Epoch 17/100, Train Loss: 0.4739, Val Loss: 0.4752\n",
      "Epoch 18/100, Train Loss: 0.4719, Val Loss: 0.4733\n",
      "Epoch 19/100, Train Loss: 0.4701, Val Loss: 0.4717\n",
      "Epoch 20/100, Train Loss: 0.4685, Val Loss: 0.4702\n",
      "Epoch 21/100, Train Loss: 0.4670, Val Loss: 0.4689\n",
      "Epoch 22/100, Train Loss: 0.4658, Val Loss: 0.4677\n",
      "Epoch 23/100, Train Loss: 0.4646, Val Loss: 0.4667\n",
      "Epoch 24/100, Train Loss: 0.4635, Val Loss: 0.4657\n",
      "Epoch 25/100, Train Loss: 0.4626, Val Loss: 0.4648\n",
      "Epoch 26/100, Train Loss: 0.4617, Val Loss: 0.4640\n",
      "Epoch 27/100, Train Loss: 0.4608, Val Loss: 0.4633\n",
      "Epoch 28/100, Train Loss: 0.4600, Val Loss: 0.4626\n",
      "Epoch 29/100, Train Loss: 0.4593, Val Loss: 0.4620\n",
      "Epoch 30/100, Train Loss: 0.4586, Val Loss: 0.4614\n",
      "Epoch 31/100, Train Loss: 0.4580, Val Loss: 0.4608\n",
      "Epoch 32/100, Train Loss: 0.4573, Val Loss: 0.4603\n",
      "Epoch 33/100, Train Loss: 0.4567, Val Loss: 0.4598\n",
      "Epoch 34/100, Train Loss: 0.4562, Val Loss: 0.4593\n",
      "Epoch 35/100, Train Loss: 0.4556, Val Loss: 0.4589\n",
      "Epoch 36/100, Train Loss: 0.4551, Val Loss: 0.4585\n",
      "Epoch 37/100, Train Loss: 0.4546, Val Loss: 0.4581\n",
      "Epoch 38/100, Train Loss: 0.4541, Val Loss: 0.4577\n",
      "Epoch 39/100, Train Loss: 0.4536, Val Loss: 0.4573\n",
      "Epoch 40/100, Train Loss: 0.4531, Val Loss: 0.4570\n",
      "Epoch 41/100, Train Loss: 0.4527, Val Loss: 0.4566\n",
      "Epoch 42/100, Train Loss: 0.4523, Val Loss: 0.4563\n",
      "Epoch 43/100, Train Loss: 0.4519, Val Loss: 0.4560\n",
      "Epoch 44/100, Train Loss: 0.4514, Val Loss: 0.4557\n",
      "Epoch 45/100, Train Loss: 0.4510, Val Loss: 0.4554\n",
      "Epoch 46/100, Train Loss: 0.4506, Val Loss: 0.4551\n",
      "Epoch 47/100, Train Loss: 0.4503, Val Loss: 0.4549\n",
      "Epoch 48/100, Train Loss: 0.4499, Val Loss: 0.4546\n",
      "Epoch 49/100, Train Loss: 0.4495, Val Loss: 0.4544\n",
      "Epoch 50/100, Train Loss: 0.4491, Val Loss: 0.4541\n",
      "Epoch 51/100, Train Loss: 0.4488, Val Loss: 0.4539\n",
      "Epoch 52/100, Train Loss: 0.4484, Val Loss: 0.4536\n",
      "Epoch 53/100, Train Loss: 0.4481, Val Loss: 0.4534\n",
      "Epoch 54/100, Train Loss: 0.4478, Val Loss: 0.4532\n",
      "Epoch 55/100, Train Loss: 0.4474, Val Loss: 0.4530\n",
      "Epoch 56/100, Train Loss: 0.4471, Val Loss: 0.4528\n",
      "Epoch 57/100, Train Loss: 0.4468, Val Loss: 0.4526\n",
      "Epoch 58/100, Train Loss: 0.4465, Val Loss: 0.4524\n",
      "Epoch 59/100, Train Loss: 0.4462, Val Loss: 0.4522\n",
      "Epoch 60/100, Train Loss: 0.4459, Val Loss: 0.4520\n",
      "Epoch 61/100, Train Loss: 0.4456, Val Loss: 0.4518\n",
      "Epoch 62/100, Train Loss: 0.4453, Val Loss: 0.4517\n",
      "Epoch 63/100, Train Loss: 0.4450, Val Loss: 0.4515\n",
      "Epoch 64/100, Train Loss: 0.4447, Val Loss: 0.4514\n",
      "Epoch 65/100, Train Loss: 0.4444, Val Loss: 0.4512\n",
      "Epoch 66/100, Train Loss: 0.4441, Val Loss: 0.4510\n",
      "Epoch 67/100, Train Loss: 0.4439, Val Loss: 0.4509\n",
      "Epoch 68/100, Train Loss: 0.4436, Val Loss: 0.4507\n",
      "Epoch 69/100, Train Loss: 0.4433, Val Loss: 0.4506\n",
      "Epoch 70/100, Train Loss: 0.4431, Val Loss: 0.4504\n",
      "Epoch 71/100, Train Loss: 0.4428, Val Loss: 0.4503\n",
      "Epoch 72/100, Train Loss: 0.4426, Val Loss: 0.4502\n",
      "Epoch 73/100, Train Loss: 0.4423, Val Loss: 0.4501\n",
      "Epoch 74/100, Train Loss: 0.4421, Val Loss: 0.4499\n",
      "Epoch 75/100, Train Loss: 0.4419, Val Loss: 0.4498\n",
      "Epoch 76/100, Train Loss: 0.4416, Val Loss: 0.4497\n",
      "Epoch 77/100, Train Loss: 0.4414, Val Loss: 0.4496\n",
      "Epoch 78/100, Train Loss: 0.4412, Val Loss: 0.4495\n",
      "Epoch 79/100, Train Loss: 0.4409, Val Loss: 0.4494\n",
      "Epoch 80/100, Train Loss: 0.4407, Val Loss: 0.4492\n",
      "Epoch 81/100, Train Loss: 0.4404, Val Loss: 0.4491\n",
      "Epoch 82/100, Train Loss: 0.4403, Val Loss: 0.4490\n",
      "Epoch 83/100, Train Loss: 0.4401, Val Loss: 0.4489\n",
      "Epoch 84/100, Train Loss: 0.4399, Val Loss: 0.4488\n",
      "Epoch 85/100, Train Loss: 0.4397, Val Loss: 0.4487\n",
      "Epoch 86/100, Train Loss: 0.4394, Val Loss: 0.4486\n",
      "Epoch 87/100, Train Loss: 0.4393, Val Loss: 0.4485\n",
      "Epoch 88/100, Train Loss: 0.4391, Val Loss: 0.4484\n",
      "Epoch 89/100, Train Loss: 0.4389, Val Loss: 0.4483\n",
      "Epoch 90/100, Train Loss: 0.4387, Val Loss: 0.4483\n",
      "Epoch 91/100, Train Loss: 0.4385, Val Loss: 0.4482\n",
      "Epoch 92/100, Train Loss: 0.4383, Val Loss: 0.4481\n",
      "Epoch 93/100, Train Loss: 0.4382, Val Loss: 0.4480\n",
      "Epoch 94/100, Train Loss: 0.4380, Val Loss: 0.4479\n",
      "Epoch 95/100, Train Loss: 0.4378, Val Loss: 0.4478\n",
      "Epoch 96/100, Train Loss: 0.4376, Val Loss: 0.4478\n",
      "Epoch 97/100, Train Loss: 0.4375, Val Loss: 0.4477\n",
      "Epoch 98/100, Train Loss: 0.4373, Val Loss: 0.4477\n",
      "Epoch 99/100, Train Loss: 0.4372, Val Loss: 0.4476\n",
      "Epoch 100/100, Train Loss: 0.4370, Val Loss: 0.4475\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = BCE_loss(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = BCE_loss(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(val_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8004f-450e-4832-9d48-d1dc146b8b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2c04d-c4bd-4563-b1c2-81b5a1aa7221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339bb21e-74a3-4ec7-8a57-76bfd24a02a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
