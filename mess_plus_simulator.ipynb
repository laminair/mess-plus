{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Simulations for the MESS+ estimator",
   "id": "6061898d87df3119"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T20:57:37.308888Z",
     "start_time": "2025-05-11T20:57:37.266855Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from classifier.model import MultilabelBERTClassifier\n",
    "from classifier.file_reader import read_files_from_folder\n",
    "from classifier.dataset import create_bert_datasets, preprocess_dataframe\n",
    "\n",
    "from utils.mess_plus import sample_from_bernoulli\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T20:57:37.483027Z",
     "start_time": "2025-05-11T20:57:37.451572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BENCHMARK_NAME = \"winogrande\"\n",
    "# this refers to whether we want to use a pre-trained classifier or learn the classifier online while benchmarking.\n",
    "APPROACH = \"online\"  # alt: online\n",
    "# This only has an effect when APPROACH = pretrained. Make sure to adjust the minibatch size accordingly!\n",
    "NUM_PRETRAINING_STEPS = 400\n",
    "SEEDS = [42]\n",
    "NUM_CLASSIFIER_LABELS = 3\n",
    "\n",
    "PROJECT_ROOT_PATH = Path(\"mess_plus_simulator\").parent"
   ],
   "id": "d29c03961de10500",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load benchmark config",
   "id": "6b3662ffb2169cb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T20:57:37.828222Z",
     "start_time": "2025-05-11T20:57:37.749519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if APPROACH == \"pretrained\":\n",
    "\tconfig_path = Path(f\"{PROJECT_ROOT_PATH}/config/pretrained/{BENCHMARK_NAME}.yaml\")\n",
    "elif APPROACH == \"online\":\n",
    "\tconfig_path = Path(f\"{PROJECT_ROOT_PATH}/config/online/{BENCHMARK_NAME}.yaml\")\n",
    "\tNUM_PRETRAINING_STEPS = 0\n",
    "else:\n",
    "\traise NotImplementedError(f\"Approach {APPROACH} not implemented.\")\n",
    "\n",
    "with config_path.open(\"r\") as f:\n",
    "\tCONFIG = yaml.safe_load(f)\n",
    "\tdisplay(CONFIG)\n"
   ],
   "id": "2d42110779bf1648",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_name': 'baseline',\n",
       " 'seed': 43,\n",
       " 'model_zoo': {'meta-llama/Llama-3.2-1B-Instruct': {'category': 'small',\n",
       "   'gpu_indices': [0],\n",
       "   'max_seq_len': 2048,\n",
       "   'gpu_memory_utilization': 0.12,\n",
       "   'quantization': None},\n",
       "  'unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit': {'category': 'medium',\n",
       "   'gpu_indices': [0],\n",
       "   'max_seq_len': 2048,\n",
       "   'gpu_memory_utilization': 0.15,\n",
       "   'quantization': 'bitsandbytes'},\n",
       "  'unsloth/Llama-3.3-70B-Instruct-bnb-4bit': {'category': 'large',\n",
       "   'gpu_indices': [0],\n",
       "   'max_seq_len': 2048,\n",
       "   'gpu_memory_utilization': 0.68,\n",
       "   'quantization': 'bitsandbytes'}},\n",
       " 'classifier_model': {'model_id': 'answerdotai/ModernBERT-base',\n",
       "  'epochs': 1,\n",
       "  'learning_rate': 0.066,\n",
       "  'weight_decay': 0.01,\n",
       "  'momentum': 0.9,\n",
       "  'batch_size': 64,\n",
       "  'max_length': 64,\n",
       "  'warmup_ratio': 0.1,\n",
       "  'threshold': 0.5,\n",
       "  'dropout_rate': 0.1,\n",
       "  'freeze_bert_layers': True,\n",
       "  'memory_size': 0,\n",
       "  'memory_strategy': 'random',\n",
       "  'reset_optimizer': False,\n",
       "  'regularization_lambda': 0.0,\n",
       "  'gpu_index': 0,\n",
       "  'disable_tqdm': True,\n",
       "  'checkpoint_path': 'checkpoints/winogrande',\n",
       "  'use_pretrained_classifier': False,\n",
       "  'scoring_method': 'raw',\n",
       "  'validation_dataset_size': 0.1,\n",
       "  'generate_training_dataset': False,\n",
       "  'write_training_dataset_to_disk': False},\n",
       " 'algorithm': {'alpha_values': [0.65, 0.7, 0.75],\n",
       "  'alpha': 0.75,\n",
       "  'c': 1,\n",
       "  'V': 0.01},\n",
       " 'lm_eval': {'benchmarks': ['winogrande'],\n",
       "  'num_repeats': 1,\n",
       "  'limit_num_samples': None,\n",
       "  'enforce_eager': True,\n",
       "  'write_to_disk': False}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load dataset",
   "id": "2b25daed58b959c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T20:57:39.295178Z",
     "start_time": "2025-05-11T20:57:39.230849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_df = read_files_from_folder(folder_path=f\"{PROJECT_ROOT_PATH}/data/inference_outputs/{BENCHMARK_NAME}\")\n",
    "input_df[\"idx_original\"] = input_df.index\n",
    "input_df = input_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "display(f\"Loaded dataframe with {input_df.shape[0]} rows and {input_df.shape[1]} columns\")\n",
    "display(f\"{len(input_df.columns.tolist())} available columns: {input_df.columns.tolist()}\")\n",
    "display(input_df.head())"
   ],
   "id": "b1c8ccffd82859a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loaded dataframe with 1267 rows and 15 columns'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"15 available columns: ['input_text', 'benchmark_name', 'label_small', 'acc_small', 'energy_consumption_small', 'inference_time_small', 'label_medium', 'acc_medium', 'energy_consumption_medium', 'inference_time_medium', 'label_large', 'acc_large', 'energy_consumption_large', 'inference_time_large', 'idx_original']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                                          input_text benchmark_name  \\\n",
       "0  Donald had to drive Matthew to the doctor imme...     winogrande   \n",
       "1  The dancer would leave the stage and enter the...     winogrande   \n",
       "2  Christopher was able to travel abroad, while W...     winogrande   \n",
       "3  The sponges performed worse at cleaning the tu...     winogrande   \n",
       "4  Erin was sick of the pests like Amy always cut...     winogrande   \n",
       "\n",
       "   label_small  acc_small  energy_consumption_small  inference_time_small  \\\n",
       "0          0.0        0.0                    37.128              0.216491   \n",
       "1          0.0        0.0                    39.052              0.227257   \n",
       "2          1.0        1.0                    39.618              0.220684   \n",
       "3          0.0        0.0                    40.061              0.217072   \n",
       "4          0.0        0.0                    71.632              0.222031   \n",
       "\n",
       "   label_medium  acc_medium  energy_consumption_medium  inference_time_medium  \\\n",
       "0           1.0         1.0                    199.450               1.022478   \n",
       "1           1.0         1.0                    199.287               1.023072   \n",
       "2           1.0         1.0                    195.672               1.018793   \n",
       "3           0.0         0.0                    196.734               1.020303   \n",
       "4           1.0         1.0                    193.776               1.021516   \n",
       "\n",
       "   label_large  acc_large  energy_consumption_large  inference_time_large  \\\n",
       "0          1.0        1.0                  1037.318              2.730692   \n",
       "1          1.0        1.0                  1004.743              2.726789   \n",
       "2          1.0        1.0                  1001.786              2.722344   \n",
       "3          0.0        0.0                  1009.372              2.727702   \n",
       "4          1.0        1.0                  1010.072              2.730747   \n",
       "\n",
       "   idx_original  \n",
       "0          1102  \n",
       "1           869  \n",
       "2           879  \n",
       "3           317  \n",
       "4           433  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>benchmark_name</th>\n",
       "      <th>label_small</th>\n",
       "      <th>acc_small</th>\n",
       "      <th>energy_consumption_small</th>\n",
       "      <th>inference_time_small</th>\n",
       "      <th>label_medium</th>\n",
       "      <th>acc_medium</th>\n",
       "      <th>energy_consumption_medium</th>\n",
       "      <th>inference_time_medium</th>\n",
       "      <th>label_large</th>\n",
       "      <th>acc_large</th>\n",
       "      <th>energy_consumption_large</th>\n",
       "      <th>inference_time_large</th>\n",
       "      <th>idx_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald had to drive Matthew to the doctor imme...</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.128</td>\n",
       "      <td>0.216491</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.450</td>\n",
       "      <td>1.022478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1037.318</td>\n",
       "      <td>2.730692</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dancer would leave the stage and enter the...</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.052</td>\n",
       "      <td>0.227257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.287</td>\n",
       "      <td>1.023072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1004.743</td>\n",
       "      <td>2.726789</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christopher was able to travel abroad, while W...</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.618</td>\n",
       "      <td>0.220684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>195.672</td>\n",
       "      <td>1.018793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.786</td>\n",
       "      <td>2.722344</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The sponges performed worse at cleaning the tu...</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.061</td>\n",
       "      <td>0.217072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>196.734</td>\n",
       "      <td>1.020303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.372</td>\n",
       "      <td>2.727702</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erin was sick of the pests like Amy always cut...</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.632</td>\n",
       "      <td>0.222031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.776</td>\n",
       "      <td>1.021516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1010.072</td>\n",
       "      <td>2.730747</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load, configure, and train classifier",
   "id": "143a3332d4e0264c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T20:57:53.675422Z",
     "start_time": "2025-05-11T20:57:49.869697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_col = \"input_text\"\n",
    "label_cols = [\"label_small\", \"label_medium\", \"label_large\"]\n",
    "\n",
    "classifier = MultilabelBERTClassifier(num_labels=NUM_CLASSIFIER_LABELS, **CONFIG[\"classifier_model\"])\n",
    "training_df = input_df.loc[:NUM_PRETRAINING_STEPS]\n",
    "training_df = preprocess_dataframe(training_df, label_cols=label_cols)\n",
    "\n",
    "train_dataset, val_dataset, tokenizer = create_bert_datasets(\n",
    "\ttraining_df,\n",
    "\ttext_col,\n",
    "\tlabel_cols,\n",
    "\tmodel_name=CONFIG[\"classifier_model\"][\"model_id\"],\n",
    "\tmax_length=CONFIG[\"classifier_model\"][\"max_length\"],\n",
    "\tval_ratio=CONFIG[\"classifier_model\"][\"validation_dataset_size\"],\n",
    "\trandom_seed=SEEDS[0],\n",
    ")\n",
    "\n",
    "training_stats = classifier.fit(train_dataset, val_dataset, epochs=CONFIG[\"classifier_model\"][\"epochs\"], early_stopping_patience=2)\n",
    "\n",
    "display(training_stats)\n"
   ],
   "id": "10a446db5d2aedca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:classifier.model:Using device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-11 16:57:49,918] [zeus.device.gpu.nvidia](nvidia.py:50) pynvml is available but could not initialize NVML: NVML Shared Library Not Found.\n",
      "[2025-05-11 16:57:49,939] [zeus.device.gpu.amd](amd.py:42) amdsmi is not available.\n",
      "[2025-05-11 16:57:49,940] [zeus.device.cpu.rapl](rapl.py:134) RAPL is not supported on this CPU.\n",
      "[2025-05-11 16:57:49,940] [zeus.monitor.energy](energy.py:208) Monitoring GPU indices [].\n",
      "[2025-05-11 16:57:49,941] [zeus.monitor.energy](energy.py:209) Monitoring CPU indices []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/herbert/code/mess-plus/venv/lib/python3.11/site-packages/torch/utils/data/dataset.py:473: UserWarning: Length of split at index 1 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "INFO:classifier.model:Initializing custom BERTClassifier: answerdotai/ModernBERT-base with 3 labels\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 18\u001B[0m\n\u001B[1;32m      6\u001B[0m training_df \u001B[38;5;241m=\u001B[39m preprocess_dataframe(training_df, label_cols\u001B[38;5;241m=\u001B[39mlabel_cols)\n\u001B[1;32m      8\u001B[0m train_dataset, val_dataset, tokenizer \u001B[38;5;241m=\u001B[39m create_bert_datasets(\n\u001B[1;32m      9\u001B[0m \ttraining_df,\n\u001B[1;32m     10\u001B[0m \ttext_col,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m \trandom_seed\u001B[38;5;241m=\u001B[39mSEEDS[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m     16\u001B[0m )\n\u001B[0;32m---> 18\u001B[0m training_stats \u001B[38;5;241m=\u001B[39m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCONFIG\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mclassifier_model\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mepochs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping_patience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m display(training_stats)\n",
      "File \u001B[0;32m~/code/mess-plus/classifier/model.py:314\u001B[0m, in \u001B[0;36mMultilabelBERTClassifier.fit\u001B[0;34m(self, train_dataset, val_dataset, epochs, early_stopping_patience, ctr, online_learn)\u001B[0m\n\u001B[1;32m    311\u001B[0m         all_labels\u001B[38;5;241m.\u001B[39mappend(labels)\n\u001B[1;32m    313\u001B[0m \u001B[38;5;66;03m# Combine predictions and calculate metrics\u001B[39;00m\n\u001B[0;32m--> 314\u001B[0m all_preds \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_preds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    315\u001B[0m all_labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack(all_labels)\n\u001B[1;32m    317\u001B[0m avg_val_loss \u001B[38;5;241m=\u001B[39m val_loss \u001B[38;5;241m/\u001B[39m val_steps\n",
      "File \u001B[0;32m~/code/mess-plus/venv/lib/python3.11/site-packages/numpy/core/shape_base.py:289\u001B[0m, in \u001B[0;36mvstack\u001B[0;34m(tup, dtype, casting)\u001B[0m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arrs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    288\u001B[0m     arrs \u001B[38;5;241m=\u001B[39m [arrs]\n\u001B[0;32m--> 289\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_nx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcasting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcasting\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: need at least one array to concatenate"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T20:58:56.277183Z",
     "start_time": "2025-05-11T20:58:56.257646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset statistics\n",
    "display(input_df[NUM_PRETRAINING_STEPS:][\"energy_consumption_small\"].mean())\n",
    "display(input_df[NUM_PRETRAINING_STEPS:][\"energy_consumption_medium\"].mean())\n",
    "display(input_df[NUM_PRETRAINING_STEPS:][\"energy_consumption_large\"].mean())\n"
   ],
   "id": "ff5f5bf045c8630",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.97596491926114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.4501996855145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1018.4225753717942"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bc2321a3d93af5cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "algorithm_config = CONFIG[\"algorithm\"]\n",
    "\n",
    "model_categories = [i for i in CONFIG[\"model_zoo\"].keys()]\n",
    "sample_cols = input_df.columns.tolist()\n",
    "\n",
    "ALPHA_VALUES = algorithm_config[\"alpha_values\"]\n",
    "C_VALUES = [1.0]\n",
    "V_VALUES = [0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "R_VALUES = [1]\n",
    "\n",
    "for alpha in ALPHA_VALUES:\n",
    "\tfor c in C_VALUES:\n",
    "\t\tfor v in V_VALUES:\n",
    "\t\t\talgorithm_config[\"V\"] = v\n",
    "\t\t\talgorithm_config[\"alpha\"] = alpha\n",
    "\t\t\talgorithm_config[\"c\"] = c\n",
    "\n",
    "\t\t\tACCURACY_LIST = []\n",
    "\t\t\tEXPLORATION_STEP_LIST = []\n",
    "\t\t\tENERGY_CONSUMPTION_LIST = []\n",
    "\t\t\tINFERENCE_TIME_LIST = []\n",
    "\t\t\tMODEL_CHOSEN_LIST = []\n",
    "\n",
    "\t\t\tENERGY_PER_MODEL = {\n",
    "\t\t\t\t\"small\": [0.01],\n",
    "\t\t\t\t\"medium\": [0.1],\n",
    "\t\t\t\t\"large\": [1.0],\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tmodel_category_list = [i for i in ENERGY_PER_MODEL.keys()]\n",
    "\n",
    "\t\t\tQ = 0.0\n",
    "\t\t\tctr = 0\n",
    "\n",
    "\t\t\trun = wandb.init(\n",
    "\t\t\t\tproject=f\"mess-plus_runs_vTEST2\",\n",
    "\t\t\t\tname=f\"{BENCHMARK_NAME}_V={algorithm_config['V']}_a={algorithm_config['alpha']}_c={algorithm_config['c']}_r={r}\",\n",
    "\t\t\t\tconfig=CONFIG\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\tif wandb.run is not None:\n",
    "\t\t\t\trun.summary.update({**{f\"classifier/{k}\": v for k, v in training_stats.items()}})\n",
    "\n",
    "\t\t\tmonitoring_dict = {}\n",
    "\t\t\tfor idx, sample in input_df[NUM_PRETRAINING_STEPS:].iterrows():\n",
    "\t\t\t\tp_t, x_t = sample_from_bernoulli(c=algorithm_config[\"c\"], timestamp=idx)\n",
    "\t\t\t\tEXPLORATION_STEP_LIST.append(x_t)\n",
    "\n",
    "\t\t\t\tif x_t == 1:\n",
    "\t\t\t\t\tresult = sample[\"label_large\"]\n",
    "\t\t\t\t\tACCURACY_LIST.append(result)\n",
    "\t\t\t\t\tstep_energy = sum([sample[i] for i in sample_cols if \"energy\" in i])\n",
    "\t\t\t\t\tstep_time = sum([sample[i] for i in sample_cols if \"inference\" in i])\n",
    "\t\t\t\t\tENERGY_CONSUMPTION_LIST.append(step_energy)\n",
    "\t\t\t\t\tINFERENCE_TIME_LIST.append(step_time)\n",
    "\t\t\t\t\tfor i in ENERGY_PER_MODEL.keys():\n",
    "\t\t\t\t\t\tENERGY_PER_MODEL[i] = sample[f\"energy_consumption_{i}\"]\n",
    "\n",
    "\t\t\t\t\tmonitoring_dict[f\"mess_plus/energy\"] = step_energy\n",
    "\t\t\t\t\tmonitoring_dict[f\"mess_plus/chosen_model\"] = len(model_category_list) - 1\n",
    "\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tpreds, probs = classifier.predict(texts=[sample[\"input_text\"]])\n",
    "\t\t\t\t\tenergy = pd.DataFrame(ENERGY_PER_MODEL, index=[0]).to_numpy()\n",
    "\n",
    "\t\t\t\t\tenergy = np.array(energy).reshape(-1, 1)\n",
    "\t\t\t\t\tprobs = probs.reshape(-1, 1)\n",
    "\n",
    "\t\t\t\t\tcost_fn = algorithm_config[\"V\"] * energy + Q * (alpha - probs)\n",
    "\t\t\t\t\tcost_fn = cost_fn.reshape(1, -1)\n",
    "\t\t\t\t\tchosen_model_id = np.argmin(cost_fn)\n",
    "\t\t\t\t\t# print(f\"STEP={ctr} - V={v} - Q={Q} - CHOSEN MODEL: {chosen_model_id} - COST FN: {cost_fn}\")\n",
    "\t\t\t\t\tmodel_category_chosen = model_category_list[chosen_model_id]\n",
    "\n",
    "\t\t\t\t\tresult = sample[f\"label_{model_category_chosen}\"]\n",
    "\t\t\t\t\tstep_energy = sample[f\"energy_consumption_{model_category_chosen}\"]\n",
    "\t\t\t\t\tstep_time = sample[f\"inference_time_{model_category_chosen}\"]\n",
    "\n",
    "\t\t\t\t\tINFERENCE_TIME_LIST.append(step_time)\n",
    "\t\t\t\t\tENERGY_CONSUMPTION_LIST.append(step_energy)\n",
    "\t\t\t\t\tMODEL_CHOSEN_LIST.append(chosen_model_id)\n",
    "\n",
    "\t\t\t\t\tmonitoring_dict[f\"mess_plus/energy\"] = step_energy\n",
    "\t\t\t\t\tmonitoring_dict[f\"mess_plus/chosen_model\"] = chosen_model_id\n",
    "\n",
    "\t\t\t\t\tACCURACY_LIST.append(result)\n",
    "\n",
    "\t\t\t\tQ = max(0.0, Q + algorithm_config[\"alpha\"] - result)\n",
    "\n",
    "\t\t\t\tx = np.array(MODEL_CHOSEN_LIST)\n",
    "\t\t\t\tmonitoring_dict.update({\n",
    "\t\t\t\t\t\"mess_plus/p_t\": p_t,\n",
    "\t\t\t\t\t\"mess_plus/x_t\": x_t,\n",
    "\t\t\t\t\t\"mess_plus/exploration_step_ratio\": sum(EXPLORATION_STEP_LIST) / (ctr + 1),\n",
    "\t\t\t\t\t\"mess_plus/q_length\": Q,\n",
    "\t\t\t\t\t\"mess_plus/accuracy\": sum(ACCURACY_LIST) / (ctr + 1),\n",
    "\t\t\t\t\t\"mess_plus/step_time\": step_time,\n",
    "\t\t\t\t\t\"mess_plus/total_runtime\": sum(INFERENCE_TIME_LIST),\n",
    "\t\t\t\t\t\"mess_plus/step_energy_consumption\": step_energy,\n",
    "\t\t\t\t\t\"models/small_chosen\": len(np.where(x == 0)[0]) / (len(x) + 1e-8),\n",
    "\t\t\t\t\t\"models/medium_chosen\": len(np.where(x == 1)[0]) / (len(x) + 1e-8),\n",
    "\t\t\t\t\t\"models/large_chosen\": len(np.where(x == 2)[0]) / (len(x) + 1e-8),\n",
    "\t\t\t\t})\n",
    "\n",
    "\t\t\t\tprint(monitoring_dict)\n",
    "\n",
    "\t\t\t\tctr += 1\n",
    "\t\t\t\tif wandb.run is not None:\n",
    "\t\t\t\t\twandb.log(monitoring_dict, step=ctr)\n",
    "\n",
    "\t\t\t\tif ctr % 3 == 0 and ctr > 0:\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tif wandb.run is not None:\n",
    "\t\t\t\twandb.finish()\n",
    "\t\t\t\ttime.sleep(2)\n",
    "\n",
    "\n",
    "print(f\"DONE\")"
   ],
   "id": "6058fd7e84add86c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c3c4fcb1c67955d0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
