{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2029d9cb-1783-410e-82a2-a5aaa2ac6f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T15:49:41.508966Z",
     "start_time": "2024-12-20T15:49:41.497764Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import textstat\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "from utils.gpu_management import reset_vllm_gpu_environment\n",
    "\n",
    "from zeus.monitor import ZeusMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65cfc21a-c1d5-4a4c-b0a7-2d7248130446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T15:49:41.517240Z",
     "start_time": "2024-12-20T15:49:41.507675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "cuDNN version: None\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "\n",
    "with open(f\"{Path.home()}/.cache/huggingface/token\", \"r\") as f:\n",
    "    HF_TOKEN = f.read()\n",
    "    f.close()\n",
    "\n",
    "\n",
    "MODELS = [\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\", \n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "]\n",
    "\n",
    "MAX_SEQ_LEN = 8192\n",
    "NUM_SAMPLES = 10_000\n",
    "NUM_BATCHES = 50\n",
    "SAMPLES_PER_BATCH = NUM_SAMPLES / NUM_BATCHES\n",
    "\n",
    "# See for reference: https://docs.vllm.ai/en/v0.5.5/dev/sampling_params.html\n",
    "SAMPLING_PARAMS = SamplingParams(\n",
    "    temperature=0.8, \n",
    "    top_p=0.95,\n",
    "    min_tokens=1,  # this is key as some models may refuse to generate anything if set to 0.\n",
    "    max_tokens=128,\n",
    ")\n",
    "\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "\n",
    "CSV_FILE_PATH = Path(f\"data/simulation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a76929-c7fc-4bd6-a057-ccc7fef2b137",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-20T15:49:41.525934Z",
     "start_time": "2024-12-20T15:49:41.522179Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_instruction(sentence_pair, tokenizer: AutoTokenizer = None):\n",
    "\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful chatbot that translates text from German to English. Only provide the translation, nothing else.\"},\n",
    "        {\"role\": \"user\", \"content\": {sentence_pair['translation']['de']}}\n",
    "        # {\"role\": \"user\", \"content\": f\"Please translate the following sentence from German to English: \\n\\n{sentence_pair['translation']['de']}\"}\n",
    "    ]\n",
    "\n",
    "    sentence_pair[\"input_formatted\"] = tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "    sentence_pair[\"target\"] = sentence_pair[\"translation\"][\"en\"]\n",
    "    \n",
    "    return sentence_pair\n",
    "\n",
    "\n",
    "def compute_text_metrics(row):\n",
    "\n",
    "    text = row[\"input_text\"]\n",
    "\n",
    "    row[\"flesch_reading_ease\"] = textstat.flesch_reading_ease(text)\n",
    "    row[\"smog_index\"] = textstat.smog_index(text)\n",
    "    row[\"automated_readability_index\"] = textstat.automated_readability_index(text)\n",
    "    row[\"lexical_diversity\"] = len(set(text.split())) / len(text.split()) if len(text.split()) > 0 else 0\n",
    "    row[\"syllable_count\"] = textstat.syllable_count(text)\n",
    "    row[\"complex_word_count\"] = textstat.difficult_words(text)\n",
    "    row[\"avg_word_length\"] = sum(len(word) for word in text.split()) / len(text.split()) if len(text.split()) > 0 else 0\n",
    "    row[\"sentence_length\"] = len(text.split())\n",
    "    row[\"flesch_kincaid_grade\"] = textstat.flesch_kincaid_grade(text)\n",
    "    row[\"coleman_liau_index\"] = textstat.coleman_liau_index(text)\n",
    "    row[\"dale_chall_readability_score\"] = textstat.dale_chall_readability_score(text)\n",
    "    row[\"linsear_write_formula\"] = textstat.linsear_write_formula(text)\n",
    "    row[\"text_standard\"] = textstat.text_standard(text)\n",
    "    row[\"fernandez_huerta\"] = textstat.fernandez_huerta(text)\n",
    "    row[\"szigriszt_pazos\"] = textstat.szigriszt_pazos(text)\n",
    "    row[\"gutierrez_polini\"] = textstat.gutierrez_polini(text)\n",
    "    row[\"crawford\"] = textstat.crawford(text)\n",
    "\n",
    "    try:\n",
    "        row[\"gulpease_index\"] = textstat.gulpease_index(text)\n",
    "    except ZeroDivisionError:\n",
    "        row[\"gulpease_index\"] = np.nan\n",
    "        \n",
    "    try:\n",
    "        row[\"osman\"] = textstat.osman(text)\n",
    "    except ZeroDivisionError:\n",
    "        row[\"osman\"] = np.nan\n",
    "\n",
    "    return row    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f581cdf4-bcd4-4fe8-96c2-c678513ba933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T15:53:59.426694Z",
     "start_time": "2024-12-20T15:53:30.511698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4ed68f7939849ffa9789d760c2031e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63f3632b46c84056a5f42680dcbfcbed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a622f75db2b447f5a3c8ddbd03d62075"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('wmt14', 'de-en', split='train')\n",
    "dataset = dataset.shuffle().select(range(NUM_SAMPLES))\n",
    "\n",
    "if CSV_FILE_PATH.exists():\n",
    "    print(\"Loaded file\")\n",
    "    df = pd.read_csv(CSV_FILE_PATH)\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "df[\"input_text\"] = [dataset[idx]['translation']['de'] for idx in range(len(dataset[\"translation\"]))]\n",
    "\n",
    "for model_name in MODELS: \n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding=True, truncation=True, max_length=512)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # print(tokenizer.chat_template)\n",
    "    dataset_formatted = dataset.map(lambda sentence_pair: add_instruction(sentence_pair, tokenizer))\n",
    "\n",
    "    for batch in range(NUM_BATCHES):\n",
    "\n",
    "        subset = dataset_formatted.select(range(\n",
    "            int(SAMPLES_PER_BATCH * batch), \n",
    "            int(SAMPLES_PER_BATCH * (batch + 1))\n",
    "        ))\n",
    "        \n",
    "        outputs = \"None\"\n",
    "\n",
    "        for idx, output in enumerate(outputs): \n",
    "            df.loc[df[\"input_text\"] == subset[idx]['translation']['de'], f\"output_{model_name.replace('/', '_')}\"] = output\n",
    "    \n",
    "        df.to_csv(CSV_FILE_PATH)\n",
    "\n",
    "df = df.apply(compute_text_metrics, axis=1)\n",
    "df.to_csv(CSV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c46c6f2-fb96-438c-9b56-e3a043e7198e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T15:50:09.377426Z",
     "start_time": "2024-12-20T15:50:09.371503Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
