{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2029d9cb-1783-410e-82a2-a5aaa2ac6f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:24:34.979746Z",
     "start_time": "2024-12-18T16:24:34.976154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CUDA available: True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'cuDNN version: 90100'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import wandb\n",
    "import threading\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import contextlib\n",
    "import transformers\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from power_monitoring.monitor import HWMonitor\n",
    "\n",
    "from utils.gpu_management import reset_vllm_gpu_environment\n",
    "\n",
    "display(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "display(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a296d54-7ac5-4ac2-96db-bbfade329351",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-18T16:25:09.520347Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode',\n",
       "  'en': 'Resumption of the session'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('wmt14', 'de-en', split='train')\n",
    "display(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65cfc21a-c1d5-4a4c-b0a7-2d7248130446",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{Path.home()}/.cache/huggingface/token\", \"r\") as f:\n",
    "    HF_TOKEN = f.read()\n",
    "    f.close()\n",
    "\n",
    "MODELS = [\"meta-llama/Llama-3.2-3B\"] # , \"neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16\"\n",
    "SYSTEM_PROMPT = \"Translate the following text from German to English. Make sure not to change the meaning:\"\n",
    "MAX_SEQ_LEN = 8192\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MINIBATCH_SIZE = 8\n",
    "NUM_SAMPLES = 2\n",
    "SAMPLING_PARAMS = SamplingParams(temperature=0.8, top_p=0.95)\n",
    "\n",
    "NUM_GPUS = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f15bda-d943-4fc6-8479-f0d1833daa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c83855858444779bedfe38fe693238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Translate the following text from German to English. Make sure not to change the meaning:\\n\\n\\nIch war einmal Gesundheitsminister in einem Mitgliedstaat, und ich kann Ihnen sagen, dass die Zahl der Toten, aber auch der Unfälle, in deren Folge junge Menschen gelähmt wurden, mich bis ans Ende meiner Tage verfolgen wird.',\n",
       " 'target': 'I have been Minister for Health in a Member State and I can tell you that the number of deaths, and also the number of accidents that leave young people quadriplegic will affect me for the rest of my life.'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset processing\n",
    "\n",
    "def add_instruction(sentence_pair, instruction: str = None):\n",
    "    sentence_pair[\"input\"] = f\"{instruction}\\n\\n\\n{sentence_pair['translation']['de']}\"\n",
    "    sentence_pair[\"target\"] = sentence_pair['translation']['en']\n",
    "    return sentence_pair\n",
    "\n",
    "dataset = dataset.shuffle().select(range(NUM_SAMPLES))\n",
    "dataset = dataset.map(lambda sentence_pair: add_instruction(sentence_pair, SYSTEM_PROMPT), remove_columns=['translation'])\n",
    "display(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc9d8589-da3d-474b-88c3-d5f86e55b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(dataset[\"input\"])\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\", token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a76929-c7fc-4bd6-a057-ccc7fef2b137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb8a6f4bc8d423c9a943ef5e4fa1674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "def embed_samples(sentence_pair, tokenizer): \n",
    "    sentence_pair[\"prompt\"] = tokenizer.apply_chat_template(sentence_pair[\"input\"], add_generation_prompt=True, tokenize=False)\n",
    "    return sentence_pair\n",
    "\n",
    "\n",
    "for model_name in MODELS: \n",
    "    # reset_vllm_gpu_environment()\n",
    "    \n",
    "    pipe = transformers.pipeline(\n",
    "        \"text-generation\", \n",
    "        model=model_name, \n",
    "        # model_kwargs={\"torch_dtype\": torch.bfloat16}, \n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    pipe(\"Hi, who are you?\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f581cdf4-bcd4-4fe8-96c2-c678513ba933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46c6f2-fb96-438c-9b56-e3a043e7198e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
