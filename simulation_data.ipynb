{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb7702c-928b-46d1-99f1-47c3ec13eb56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/.local/lib/python3.8/site-packages (4.44.2)\n",
      "Requirement already satisfied: datasets in /home/ubuntu/.local/lib/python3.8/site-packages (3.0.0)\n",
      "Requirement already satisfied: sentence_transformers in /home/ubuntu/.local/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.1.2)\n",
      "Requirement already satisfied: nltk in /home/ubuntu/.local/lib/python3.8/site-packages (3.9.1)\n",
      "Requirement already satisfied: accelerate in /home/ubuntu/.local/lib/python3.8/site-packages (0.34.2)\n",
      "Requirement already satisfied: wandb in /home/ubuntu/.local/lib/python3.8/site-packages (0.18.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from transformers) (1.17.4)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (from datasets) (0.25.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (2024.6.1)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from sentence_transformers) (7.0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/.local/lib/python3.8/site-packages (from sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from sentence_transformers) (2.1.0a0+41361538.nv23.6)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from sentence_transformers) (1.3.3)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/.local/lib/python3.8/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (7.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.12.0; python_version < \"3.9\" and sys_platform == \"linux\" in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb) (5.28.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb) (4.3.3)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.10\" in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb) (45.2.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb) (2.14.0)\n",
      "Requirement already satisfied: setproctitle in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.14.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets sentence_transformers matplotlib nltk accelerate wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54b97a9-af2e-4f1c-80a6-2dcdb81af9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1221e6ff-7cfa-4ac1-9dc8-aaffb9b40c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from power_monitoring.monitor import HWMonitor\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2029d9cb-1783-410e-82a2-a5aaa2ac6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e7cef4-e1f6-49bc-9e37-8b704a2ec742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29c13f5-0244-4143-ae9a-36112b8007ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: sabrina-glatz (sabrina-glatz-thesis). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93969cc-e4de-4d0e-93e6-45b0119f4ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c6a9c8-ec52-47e2-b809-9f9e6acd31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1119246c-a7ed-4d09-88b4-ec3b5a2332f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = {\n",
    "#     \"wmt14\": [],\n",
    "#     \"cnn_dailymail\": [],\n",
    "#     \"gsm8k\": []\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41fa5747-f07c-4e16-93e1-021cbfa446c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"input_output_pairs\", 'wb') as f:\n",
    "#     pickle.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a296d54-7ac5-4ac2-96db-bbfade329351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "wmt14_dataset = load_dataset('wmt14', 'de-en', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c5dbea-c979-4504-bb1a-16ec6e1e4ead",
   "metadata": {},
   "source": [
    "### Llama 3.2 - 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0193baa8-731f-440a-9277-2c4e3247a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama1b_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "llama1b = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb6bcbba-ba3a-4f5e-9738-9466418d041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = wmt14_dataset[10]['translation']['de']  \n",
    "input_prompt = \"Translate the sentence from German to English: \\n\\n\" + input_text + \"\\n\\n Write the translation here: \"\n",
    "\n",
    "inputs = llama1b_tokenizer(input_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d234142c-8518-4a12-bba9-06c9ddf3b0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Laut aktuellen Messungen durchfahren auf der B 33 täglich etwa 12 000 Fahrzeuge die Gemeinde Gutach, davon sind etwa zehn Prozent Schwerlastverkehr\", betont Arnold.\n"
     ]
    }
   ],
   "source": [
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d58410ff-e33f-49ae-b45f-66f9386b3bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"According to current measurements, daily approximately 12,000 vehicles pass through the B 33, of which around ten percent are heavy traffic.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_ids = llama1b.generate(\n",
    "        inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_new_tokens=50\n",
    "    )\n",
    "\n",
    "output_text = llama1b_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "answer_prefix = \"Write the translation here: \"\n",
    "if answer_prefix in output_text:\n",
    "    cleaned_output = output_text.split(answer_prefix)[-1].split('.')[0].strip() + '.'\n",
    "else:\n",
    "    cleaned_output = output_text.strip().split('.')[0] + '.'\n",
    "\n",
    "print(cleaned_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deda33a-9f21-4e46-99fa-4e4667c3a54d",
   "metadata": {},
   "source": [
    "### Llama 3.2 - 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4db769-0117-404f-9648-3272dd8588f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd89909c8a9445fae59382ac1bb8294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ac2064bd8740ac8430ca60186ae9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c865284d094e6989af60d23f619d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2076450767c3431da04b087cd265ed96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d615228da9e64739b5d97d5f4a1481a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8c3984dbee4859b3f5f2eadc516eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e6df6da9144792b3b62a2946978b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3d4a30ffdd42cfbca911a49f5f40b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb6cb7b12684edaa777f78745ddc08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559142e440d4445db8172a260f0b7fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama3b_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "llama3b = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5564fdde-c7f3-45b4-90a7-ab9810c4db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = wmt14_dataset[10]['translation']['de']  \n",
    "input_prompt = \"Translate the sentence from German to English: \\n\\n\" + input_text + \"\\n\\n Write the translation here: \"\n",
    "\n",
    "inputs = llama3b_tokenizer(input_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "629533a7-c18e-488f-b868-d966a5645c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Laut aktuellen Messungen durchfahren auf der B 33 täglich etwa 12 000 Fahrzeuge die Gemeinde Gutach, davon sind etwa zehn Prozent Schwerlastverkehr\", betont Arnold.\n"
     ]
    }
   ],
   "source": [
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6d63fca-6674-46b7-9464-aba613aea1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"According to current measurements, approximately 12,000 vehicles pass through the municipality of Gutach on the B 33 road every day, with about 10% being heavy goods traffic,\" Arnold emphasizes.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_ids = llama3b.generate(\n",
    "        inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_new_tokens=50\n",
    "    )\n",
    "\n",
    "output_text = llama3b_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "answer_prefix = \"Write the translation here: \"\n",
    "if answer_prefix in output_text:\n",
    "    cleaned_output = output_text.split(answer_prefix)[-1].split('.')[0].strip() + '.'\n",
    "else:\n",
    "    cleaned_output = output_text.strip().split('.')[0] + '.'\n",
    "\n",
    "print(cleaned_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd4eb9-c70a-4075-b370-2cf02de61b34",
   "metadata": {},
   "source": [
    "### Llama 3.2 - 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e903ffe-1884-492a-b359-f80c2ff036be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797ee133dadc4f78b8dc65319165cf83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama8b_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "llama8b = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422c7136-8cfb-48e9-91b1-4e8cc5648817",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = wmt14_dataset[10]['translation']['de']  \n",
    "input_prompt = \"Translate the sentence from German to English: \\n\\n\" + input_text + \"\\n\\n Write the translation here: \"\n",
    "\n",
    "inputs = llama8b_tokenizer(input_prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde56905-e586-47ad-b6a9-1292952cd5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Laut aktuellen Messungen durchfahren auf der B 33 täglich etwa 12 000 Fahrzeuge die Gemeinde Gutach, davon sind etwa zehn Prozent Schwerlastverkehr\", betont Arnold.\n"
     ]
    }
   ],
   "source": [
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f276e54b-f1bb-408d-8274-fbbdbc3d67b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"According to current measurements, about 12,000 vehicles pass through the municipality of Gutach on the B 33 every day, of which about ten percent are heavy traffic\", Arnold emphasizes.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_ids = llama8b.generate(\n",
    "        inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_new_tokens=50\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "output_text = llama8b_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "answer_prefix = \"Write the translation here: \"\n",
    "if answer_prefix in output_text:\n",
    "    cleaned_output = output_text.split(answer_prefix)[-1].split('.')[0].strip() + '.'\n",
    "else:\n",
    "    cleaned_output = output_text.strip().split('.')[0] + '.'\n",
    "\n",
    "print(cleaned_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c91b9d7-508c-4e18-8f33-f50d5eb747ed",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90bb4ea2-427a-4334-b43d-a24139854808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"input_output_pairs\", 'rb') as f:\n",
    "    outputs = pickle.load(f)\n",
    "# print(outputs['wmt14'])\n",
    "\n",
    "for i in range(5000):\n",
    "    input_text = wmt14_dataset[i]['translation']['de']\n",
    "    outputs[\"wmt14\"].append({\n",
    "        \"input_text\": input_text,\n",
    "        \"1b\": None,\n",
    "        \"3b\": None,\n",
    "        \"8b\": None\n",
    "    })\n",
    "    \n",
    "with open(\"input_output_pairs\", 'wb') as f:\n",
    "    pickle.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b33255-544c-4fa2-82ca-30be7d024d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wmt14(model, tokenizer, dataset, output_file, num_samples, dict_type):\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        input_text = dataset[i]['translation']['de']\n",
    "        input_prompt = \"Translate the sentence from German to English: \\n\\n\" + input_text + \"\\n\\n Write the translation here: \"\n",
    "\n",
    "        inputs = tokenizer(input_prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                max_new_tokens=50\n",
    "            ).to(\"cuda\")\n",
    "\n",
    "        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        answer_prefix = \"Write the translation here: \"\n",
    "        if answer_prefix in output_text:\n",
    "            cleaned_output = output_text.split(answer_prefix)[-1].strip()\n",
    "        else:\n",
    "            cleaned_output = output_text.strip()\n",
    "\n",
    "        first_sentence = cleaned_output.split('.')[0] + '.' if '.' in cleaned_output else cleaned_output\n",
    "        print(f\"{dict_type} | CURRENT IDX: {i}\")\n",
    "\n",
    "        outputs[\"wmt14\"][i][dict_type] = first_sentence\n",
    "\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(outputs, f)\n",
    "\n",
    "    print(f\"Generated {num_samples} sentences for {dict_type} and saved to {output_file}.\")\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "897eb6d0-e8ff-491a-a06b-845b9103b653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: sabrina-glatz. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1248001/3472584489.py\", line 1, in <module>\n",
      "    wandb.init(project=\"MESS+\", entity=\"ryzhangofficial\")\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 1255, in init\n",
      "    wandb._sentry.reraise(e)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/wandb/analytics/sentry.py\", line 155, in reraise\n",
      "    raise exc.with_traceback(sys.exc_info()[2])\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 1241, in init\n",
      "    return wi.init()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 838, in init\n",
      "    raise error\n",
      "wandb.errors.CommError: failed to upsert bucket: returned error 403 Forbidden: {\"errors\":[{\"message\":\"permission denied\",\"path\":[\"upsertBucket\"],\"extensions\":{\"code\":\"PERMISSION_ERROR\"}}],\"data\":{\"upsertBucket\":null}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1082, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/usr/lib/python3/dist-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/usr/lib/python3/dist-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"MESS+\", entity=\"ryzhangofficial\")\n",
    "stop_event = threading.Event()\n",
    "hw_monitor = HWMonitor(monitoring_freq=1.0, stop_event=threading.Event())\n",
    "hw_monitor.start()\n",
    "\n",
    "generated_samples = generate_wmt14(llama1b, llama1b_tokenizer, wmt14_dataset, \"input_output_pairs\", 5000, \"1b\")\n",
    "\n",
    "stop_event.set() \n",
    "hw_monitor.join()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b83d19a-dd47-475e-9b43-e4d6f5551ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
